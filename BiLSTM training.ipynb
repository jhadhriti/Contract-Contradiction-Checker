{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b5cd2f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-22T16:51:15.458565Z",
     "iopub.status.busy": "2024-06-22T16:51:15.457715Z",
     "iopub.status.idle": "2024-06-22T16:51:16.726939Z",
     "shell.execute_reply": "2024-06-22T16:51:16.725950Z"
    },
    "papermill": {
     "duration": 1.277053,
     "end_time": "2024-06-22T16:51:16.729519",
     "exception": false,
     "start_time": "2024-06-22T16:51:15.452466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0278bfa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T16:51:16.737800Z",
     "iopub.status.busy": "2024-06-22T16:51:16.737405Z",
     "iopub.status.idle": "2024-06-22T16:51:37.204852Z",
     "shell.execute_reply": "2024-06-22T16:51:37.203775Z"
    },
    "papermill": {
     "duration": 20.474125,
     "end_time": "2024-06-22T16:51:37.207407",
     "exception": false,
     "start_time": "2024-06-22T16:51:16.733282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/PetrochukM/PyTorch-NLP.git\r\n",
      "  Cloning https://github.com/PetrochukM/PyTorch-NLP.git to /tmp/pip-req-build-w6n7grv9\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/PetrochukM/PyTorch-NLP.git /tmp/pip-req-build-w6n7grv9\r\n",
      "  Resolved https://github.com/PetrochukM/PyTorch-NLP.git to commit 53d7edcb8e0c099efce7c2ddf8cd7c44157fcac3\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-nlp==0.5.0) (1.26.4)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-nlp==0.5.0) (4.66.4)\r\n",
      "Building wheels for collected packages: pytorch-nlp\r\n",
      "  Building wheel for pytorch-nlp (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorch-nlp: filename=pytorch_nlp-0.5.0-py3-none-any.whl size=88718 sha256=59474a195c94750fb1a8fa10dfe6eeadd25ac8868d85bd629c30db2f4f480ba1\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-56b4w9af/wheels/a5/93/b0/9f0138afb1271281613a5af71272c5b246fdd2d421c6fbdf88\r\n",
      "Successfully built pytorch-nlp\r\n",
      "\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pytorch-nlp\r\n",
      "Successfully installed pytorch-nlp-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/PetrochukM/PyTorch-NLP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99aaef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T16:51:37.217318Z",
     "iopub.status.busy": "2024-06-22T16:51:37.216913Z",
     "iopub.status.idle": "2024-06-22T16:51:38.280133Z",
     "shell.execute_reply": "2024-06-22T16:51:38.279006Z"
    },
    "papermill": {
     "duration": 1.07105,
     "end_time": "2024-06-22T16:51:38.282559",
     "exception": false,
     "start_time": "2024-06-22T16:51:37.211509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 22 16:51:38 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   42C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   43C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfce658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T16:51:38.293273Z",
     "iopub.status.busy": "2024-06-22T16:51:38.292577Z",
     "iopub.status.idle": "2024-06-22T16:51:44.950039Z",
     "shell.execute_reply": "2024-06-22T16:51:44.949257Z"
    },
    "papermill": {
     "duration": 6.665361,
     "end_time": "2024-06-22T16:51:44.952334",
     "exception": false,
     "start_time": "2024-06-22T16:51:38.286973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Bottle(nn.Module):\n",
    "\n",
    "    def forward(self, input):\n",
    "        if len(input.size()) <= 2:\n",
    "            return super(Bottle, self).forward(input)\n",
    "        size = input.size()[:2]\n",
    "        out = super(Bottle, self).forward(input.view(size[0]*size[1], -1))\n",
    "        return out.view(size[0], size[1], -1)\n",
    "\n",
    "\n",
    "class Linear(Bottle, nn.Linear):\n",
    "    pass\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        input_size = 300\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=300,\n",
    "                        num_layers=1, dropout=0.2,\n",
    "                        bidirectional=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size()[1]\n",
    "        state_shape = 2, batch_size, 300\n",
    "        h0 = c0 = Variable(inputs.data.new(*state_shape).zero_())\n",
    "        outputs, (ht, ct) = self.rnn(inputs, (h0, c0))\n",
    "        return ht[-2:].transpose(0, 1).contiguous().view(batch_size, -1)\n",
    "\n",
    "class SNLIClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed, d_out):\n",
    "        super(SNLIClassifier, self).__init__()\n",
    "        self.embed = nn.Embedding(n_embed, 100)\n",
    "        self.projection = Linear(100, 300)\n",
    "        self.encoder = Encoder()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        seq_in_size = 4*300\n",
    "        lin_config = [seq_in_size]*2\n",
    "        self.out = nn.Sequential(\n",
    "            Linear(*lin_config),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            Linear(*lin_config),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            Linear(*lin_config),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            Linear(seq_in_size, d_out))\n",
    "\n",
    "    def forward(self, premise, hypothesis):\n",
    "        prem_embed = self.embed(premise)\n",
    "        hypo_embed = self.embed(hypothesis)\n",
    "        prem_embed = Variable(prem_embed.data)\n",
    "        hypo_embed = Variable(hypo_embed.data)  \n",
    "        prem_embed = self.relu(self.projection(prem_embed))\n",
    "        hypo_embed = self.relu(self.projection(hypo_embed))\n",
    "        premise = self.encoder(prem_embed)\n",
    "        hypothesis = self.encoder(hypo_embed)\n",
    "        scores = self.out(torch.cat([premise, hypothesis], 1))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c548dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T16:51:44.962141Z",
     "iopub.status.busy": "2024-06-22T16:51:44.961726Z",
     "iopub.status.idle": "2024-06-23T03:55:15.956955Z",
     "shell.execute_reply": "2024-06-23T03:55:15.956067Z"
    },
    "papermill": {
     "duration": 39811.003146,
     "end_time": "2024-06-23T03:55:15.959701",
     "exception": false,
     "start_time": "2024-06-22T16:51:44.956555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "snli_1.0.zip: 94.6MB [00:07, 13.4MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "glove.6B.zip: 862MB [02:39, 5.42MB/s]                           \n",
      "100%|██████████| 400000/400000 [00:27<00:00, 14564.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   298     0      1000  1000/550152       0% 0.830741 0.841028      53.6742      60.9200\n",
      "   610     0      2000  2000/550152       0% 0.889661 0.723325      57.8809      63.3500\n",
      "   928     0      3000  3000/550152       1% 0.757285 0.815956      59.9208      65.1300\n",
      "  1246     0      4000  4000/550152       1% 0.808628 0.956239      61.3703      65.7500\n",
      "  1563     1      5000   702/550152       0% 0.715099 0.845020      66.9783      67.1500\n",
      "  1881     1      6000  1702/550152       0% 0.829306 0.716270      67.1985      67.8200\n",
      "  2199     1      7000  2702/550152       0% 0.613150 0.674699      67.5197      68.4700\n",
      "  2519     1      8000  3702/550152       1% 0.633610 0.706520      67.7771      68.6100\n",
      "  2836     2      9000   404/550152       0% 0.696915 0.802008      69.4249      69.1400\n",
      "  3151     2     10000  1404/550152       0% 0.695678 0.795504      69.4673      69.0700\n",
      "  3466     2     11000  2404/550152       0% 0.799542 0.838689      69.6905      69.2300\n",
      "  3782     2     12000  3404/550152       1% 0.735561 0.824970      69.8668      69.6100\n",
      "  4099     3     13000   106/550152       0% 0.746647 0.792192      71.2338      69.5100\n",
      "  4416     3     14000  1106/550152       0% 0.752875 0.724134      71.3177      69.7900\n",
      "  4734     3     15000  2106/550152       0% 0.674097 0.879913      71.4339      69.9500\n",
      "  5051     3     16000  3106/550152       1% 0.677382 0.717940      71.5732      70.2300\n",
      "  5369     3     17000  4106/550152       1% 0.595453 0.672364      71.7416      69.9600\n",
      "  5688     4     18000   808/550152       0% 0.683142 0.838015      72.9715      69.8400\n",
      "  6008     4     19000  1808/550152       0% 0.632068 0.644164      72.9976      70.7000\n",
      "  6335     4     20000  2808/550152       1% 0.529808 0.694135      73.2313      70.4300\n",
      "  6658     4     21000  3808/550152       1% 0.541565 0.765844      73.4139      70.6000\n",
      "  6972     5     22000   510/550152       0% 0.674825 0.787143      74.4792      70.2900\n",
      "  7285     5     23000  1510/550152       0% 0.517471 0.617802      74.4862      69.7700\n",
      "  7599     5     24000  2510/550152       0% 0.628992 0.742229      74.7283      69.9600\n",
      "  7921     5     25000  3510/550152       1% 0.640599 0.652401      74.9728      70.3600\n",
      "  8245     6     26000   212/550152       0% 0.653771 0.621697      76.0761      70.1100\n",
      "  8565     6     27000  1212/550152       0% 0.713780 0.646060      76.1171      70.1300\n",
      "  8886     6     28000  2212/550152       0% 0.576444 0.630224      76.2513      70.4800\n",
      "  9212     6     29000  3212/550152       1% 0.665096 0.714856      76.4492      70.3700\n",
      "  9537     6     30000  4212/550152       1% 0.420410 0.756841      76.5788      70.1100\n",
      "  9862     7     31000   914/550152       0% 0.520584 0.977900      77.5309      70.1600\n",
      " 10186     7     32000  1914/550152       0% 0.580619 0.679636      77.5666      70.1100\n",
      " 10511     7     33000  2914/550152       1% 0.603708 0.745455      77.8491      70.3500\n",
      " 10831     7     34000  3914/550152       1% 0.611957 0.673868      77.9515      69.7100\n",
      " 11152     8     35000   616/550152       0% 0.326835 0.922019      78.7249      69.8000\n",
      " 11470     8     36000  1616/550152       0% 0.531334 0.676748      78.8178      69.8800\n",
      " 11792     8     37000  2616/550152       0% 0.387147 0.967791      79.0069      69.7900\n",
      " 12119     8     38000  3616/550152       1% 0.460864 0.987464      79.2143      69.2700\n",
      " 12447     9     39000   318/550152       0% 0.377892 0.940115      79.7907      69.2900\n",
      " 12770     9     40000  1318/550152       0% 0.511802 0.874994      80.0929      69.0600\n",
      " 13102     9     41000  2318/550152       0% 0.446423 0.785363      80.2200      70.0200\n",
      " 13427     9     42000  3318/550152       1% 0.599717 0.826742      80.4021      68.9800\n",
      " 13755    10     43000    20/550152       0% 0.428015 0.973586      81.6406      69.3500\n",
      " 14087    10     44000  1020/550152       0% 0.468647 1.141869      81.2477      69.1400\n",
      " 14412    10     45000  2020/550152       0% 0.529986 0.756899      81.3065      69.4900\n",
      " 14742    10     46000  3020/550152       1% 0.348372 0.739500      81.5043      69.5700\n",
      " 15079    10     47000  4020/550152       1% 0.371758 1.425460      81.6144      69.3000\n",
      " 15417    11     48000   722/550152       0% 0.406320 0.898370      82.3007      69.0600\n",
      " 15752    11     49000  1722/550152       0% 0.395715 0.750499      82.3003      69.1600\n",
      " 16090    11     50000  2722/550152       0% 0.443929 1.368958      82.4595      68.8900\n",
      " 16429    11     51000  3722/550152       1% 0.482889 0.986704      82.5785      68.8900\n",
      " 16778    12     52000   424/550152       0% 0.268589 1.280123      82.8586      69.2200\n",
      " 17122    12     53000  1424/550152       0% 0.405059 1.018461      83.1477      68.7300\n",
      " 17457    12     54000  2424/550152       0% 0.342850 0.885241      83.1896      68.7600\n",
      " 17792    12     55000  3424/550152       1% 0.552571 0.794899      83.3437      69.3400\n",
      " 18121    13     56000   126/550152       0% 0.427432 0.940093      84.0960      68.8700\n",
      " 18460    13     57000  1126/550152       0% 0.445056 0.868961      84.0794      68.7500\n",
      " 18806    13     58000  2126/550152       0% 0.466796 0.708134      84.1714      68.6900\n",
      " 19159    13     59000  3126/550152       1% 0.294124 1.066529      84.2625      68.4600\n",
      " 19516    13     60000  4126/550152       1% 0.468906 1.345986      84.3513      68.5200\n",
      " 19889    14     61000   828/550152       0% 0.345650 1.227022      84.8619      69.1000\n",
      " 20255    14     62000  1828/550152       0% 0.361830 0.902462      84.8246      68.7100\n",
      " 20611    14     63000  2828/550152       1% 0.417943 0.855552      84.9546      68.2600\n",
      " 20966    14     64000  3828/550152       1% 0.386503 1.127374      85.0420      68.6900\n",
      " 21343    15     65000   530/550152       0% 0.341903 0.953657      85.6766      68.5000\n",
      " 21728    15     66000  1530/550152       0% 0.484431 1.092709      85.5663      68.7900\n",
      " 22107    15     67000  2530/550152       0% 0.312463 1.651763      85.5605      68.0700\n",
      " 22492    15     68000  3530/550152       1% 0.401909 1.072472      85.6876      68.2300\n",
      " 22885    16     69000   232/550152       0% 0.384545 1.294395      86.1193      68.1700\n",
      " 23279    16     70000  1232/550152       0% 0.299334 0.703245      86.1766      68.4900\n",
      " 23682    16     71000  2232/550152       0% 0.278313 1.544736      86.1951      68.5200\n",
      " 24084    16     72000  3232/550152       1% 0.397859 1.247804      86.2655      68.0300\n",
      " 24498    16     73000  4232/550152       1% 0.278532 1.365545      86.3802      68.5200\n",
      " 24904    17     74000   934/550152       0% 0.333553 0.968061      86.9053      68.9500\n",
      " 25309    17     75000  1934/550152       0% 0.436874 1.139890      86.8012      68.4300\n",
      " 25710    17     76000  2934/550152       1% 0.427123 1.114234      86.8663      68.3600\n",
      " 26107    17     77000  3934/550152       1% 0.468655 0.927492      86.9249      68.1800\n",
      " 26537    18     78000   636/550152       0% 0.337760 0.896410      87.2359      68.5400\n",
      " 26938    18     79000  1636/550152       0% 0.281599 1.300842      87.3954      68.4900\n",
      " 27347    18     80000  2636/550152       0% 0.222185 1.541866      87.4609      67.8200\n",
      " 27766    18     81000  3636/550152       1% 0.272879 1.339350      87.5159      68.1800\n",
      " 28199    19     82000   338/550152       0% 0.310065 1.496653      87.5508      67.9800\n",
      " 28616    19     83000  1338/550152       0% 0.286196 1.313873      87.8258      68.1800\n",
      " 29040    19     84000  2338/550152       0% 0.286115 1.202606      87.8706      68.4200\n",
      " 29467    19     85000  3338/550152       1% 0.401173 1.373394      87.9737      67.7900\n",
      " 29912    20     86000    40/550152       0% 0.211778 1.300796      87.5586      68.6900\n",
      " 30371    20     87000  1040/550152       0% 0.282244 1.187786      88.3601      68.4700\n",
      " 30793    20     88000  2040/550152       0% 0.320963 1.140186      88.3391      68.2800\n",
      " 31225    20     89000  3040/550152       1% 0.260693 1.650567      88.4524      69.0000\n",
      " 31664    20     90000  4040/550152       1% 0.353879 1.151814      88.5319      68.6800\n",
      " 32122    21     91000   742/550152       0% 0.291048 1.137214      88.9267      68.1200\n",
      " 32562    21     92000  1742/550152       0% 0.276976 1.242854      88.8777      68.2600\n",
      " 32987    21     93000  2742/550152       0% 0.264707 1.505215      88.9229      67.8200\n",
      " 33448    21     94000  3742/550152       1% 0.335160 1.468408      88.9592      68.3300\n",
      " 33884    22     95000   444/550152       0% 0.214460 1.504605      89.0871      68.2500\n",
      " 34334    22     96000  1444/550152       0% 0.266098 0.914204      89.3384      68.0300\n",
      " 34792    22     97000  2444/550152       0% 0.377805 1.275323      89.2425      67.5700\n",
      " 35246    22     98000  3444/550152       1% 0.327024 1.114678      89.3281      68.1300\n",
      " 35695    23     99000   146/550152       0% 0.207653 1.290199      89.3729      67.7800\n",
      " 36143    23    100000  1146/550152       0% 0.327482 1.617047      89.4913      67.8400\n",
      " 36592    23    101000  2146/550152       0% 0.347039 1.202773      89.5059      67.9100\n",
      " 37059    23    102000  3146/550152       1% 0.294081 1.790131      89.5693      67.8400\n",
      " 37508    23    103000  4146/550152       1% 0.306436 1.286172      89.6335      68.2700\n",
      " 37960    24    104000   848/550152       0% 0.224445 1.414165      89.9128      67.7700\n",
      " 38416    24    105000  1848/550152       0% 0.319575 1.443005      89.9152      68.3800\n",
      " 38889    24    106000  2848/550152       1% 0.231604 1.441330      90.0152      67.9000\n",
      " 39348    24    107000  3848/550152       1% 0.246654 1.102536      90.0549      68.2700\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchnlp.samplers import BucketBatchSampler\n",
    "from torchnlp.datasets import snli_dataset\n",
    "from torchnlp.encoders.text import WhitespaceEncoder, stack_and_pad_tensors\n",
    "from torchnlp.encoders import LabelEncoder\n",
    "from torchnlp import word_to_vector\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "def collate_fn(batch, train=True):\n",
    "    \"\"\" list of tensors to a batch tensors \"\"\"\n",
    "    premise_batch, _ = stack_and_pad_tensors([row['premise'] for row in batch])\n",
    "    hypothesis_batch, _ = stack_and_pad_tensors([row['hypothesis'] for row in batch])\n",
    "    label_batch = torch.stack([row['label'] for row in batch])\n",
    "\n",
    "    # PyTorch RNN requires batches to be transposed for speed and integration with CUDA\n",
    "    transpose = (lambda b: b.t_().squeeze(0).contiguous())\n",
    "\n",
    "    return (transpose(premise_batch), transpose(hypothesis_batch), transpose(label_batch))\n",
    "\n",
    "def makedirs(name):\n",
    "    \"\"\"helper function for python 2 and 3 to call os.makedirs()\n",
    "       avoiding an error if the directory to be created already exists\"\"\"\n",
    "\n",
    "    import os, errno\n",
    "\n",
    "    try:\n",
    "        os.makedirs(name)\n",
    "    except OSError as ex:\n",
    "        if ex.errno == errno.EEXIST and os.path.isdir(name):\n",
    "            # ignore existing directory\n",
    "            pass\n",
    "        else:\n",
    "            # a different error happened\n",
    "            raise\n",
    "            \n",
    "# load dataset\n",
    "train, dev, test = snli_dataset(train=True, dev=True, test=True)\n",
    "\n",
    "# Preprocess\n",
    "for row in itertools.chain(train, dev, test):\n",
    "    row['premise'] = row['premise'].lower()\n",
    "    row['hypothesis'] = row['hypothesis'].lower()\n",
    "\n",
    "# Make Encoders\n",
    "sentence_corpus = [row['premise'] for row in itertools.chain(train, dev, test)]\n",
    "sentence_corpus += [row['hypothesis'] for row in itertools.chain(train, dev, test)]\n",
    "sentence_encoder = WhitespaceEncoder(sentence_corpus)\n",
    "\n",
    "label_corpus = [row['label'] for row in itertools.chain(train, dev, test)]\n",
    "label_encoder = LabelEncoder(label_corpus)\n",
    "\n",
    "# Encode\n",
    "for row in itertools.chain(train, dev, test):\n",
    "    row['premise'] = sentence_encoder.encode(row['premise'])\n",
    "    row['hypothesis'] = sentence_encoder.encode(row['hypothesis'])\n",
    "    row['label'] = label_encoder.encode(row['label'])\n",
    "\n",
    "n_embed = sentence_encoder.vocab_size\n",
    "d_out = label_encoder.vocab_size\n",
    "n_cells = 1\n",
    "\n",
    "# double the number of cells for bidirectional networks\n",
    "if True:\n",
    "    n_cells *= 2\n",
    "\n",
    "\n",
    "model = SNLIClassifier(n_embed, d_out)\n",
    "\n",
    "# Load word vectors\n",
    "word_vectors = word_to_vector.aliases['glove.6B.100d']()\n",
    "for i, token in enumerate(sentence_encoder.vocab):\n",
    "    model.embed.weight.data[i] = word_vectors[token]\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "iterations = 0\n",
    "start = time.time()\n",
    "best_dev_acc = -1\n",
    "header = '  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy'\n",
    "dev_log_template = ' '.join(\n",
    "    '{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.0f}%,{:>8.6f},{:8.6f},{:12.4f},{:12.4f}'\n",
    "    .split(','))\n",
    "log_template = ' '.join(\n",
    "    '{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.0f}%,{:>8.6f},{},{:12.4f},{}'.split(','))\n",
    "makedirs('results')\n",
    "print(header)\n",
    "\n",
    "for epoch in range(25):\n",
    "    n_correct, n_total = 0, 0\n",
    "\n",
    "    train_sampler = SequentialSampler(train)\n",
    "    train_batch_sampler = BucketBatchSampler(\n",
    "        train_sampler, 128, True, sort_key=lambda r: len(train[r]['premise']))\n",
    "    train_iterator = DataLoader(\n",
    "        train,\n",
    "        batch_sampler=train_batch_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        num_workers=0)\n",
    "    for batch_idx, (premise_batch, hypothesis_batch, label_batch) in enumerate(train_iterator):\n",
    "\n",
    "        # switch model to training mode, clear gradient accumulators\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "        # forward pass\n",
    "        answer = model(premise_batch, hypothesis_batch)\n",
    "\n",
    "        # calculate accuracy of predictions in the current batch\n",
    "        n_correct += (torch.max(answer, 1)[1].view(label_batch.size()) == label_batch).sum()\n",
    "        n_total += premise_batch.size()[1]\n",
    "        train_acc = 100. * n_correct / n_total\n",
    "\n",
    "        # calculate loss of the network output with respect to training labels\n",
    "        loss = criterion(answer, label_batch)\n",
    "\n",
    "        # backpropagate and update optimizer learning rate\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # checkpoint model periodically\n",
    "        if iterations % 1000 == 0:\n",
    "            snapshot_prefix = os.path.join('results', 'snapshot')\n",
    "            snapshot_path = snapshot_prefix + '_acc_{:.4f}_loss_{:.6f}_iter_{}_model.pt'.format(\n",
    "                train_acc, loss.item(), iterations)\n",
    "            torch.save(model, snapshot_path)\n",
    "            for f in glob.glob(snapshot_prefix + '*'):\n",
    "                if f != snapshot_path:\n",
    "                    os.remove(f)\n",
    "\n",
    "        # evaluate performance on validation set periodically\n",
    "        if iterations % 1000 == 0:\n",
    "\n",
    "            # switch model to evaluation mode\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "\n",
    "            # calculate accuracy on validation set\n",
    "            n_dev_correct, dev_loss = 0, 0\n",
    "\n",
    "            dev_sampler = SequentialSampler(dev)\n",
    "            dev_batch_sampler = BucketBatchSampler(\n",
    "                dev_sampler, 128, True, sort_key=lambda r: len(dev[r]['premise']))\n",
    "            dev_iterator = DataLoader(\n",
    "                dev,\n",
    "                batch_sampler=dev_batch_sampler,\n",
    "                collate_fn=partial(collate_fn, train=False),\n",
    "                pin_memory=torch.cuda.is_available(),\n",
    "                num_workers=0)\n",
    "            for dev_batch_idx, (premise_batch, hypothesis_batch,\n",
    "                                label_batch) in enumerate(dev_iterator):\n",
    "                answer = model(premise_batch, hypothesis_batch)\n",
    "                n_dev_correct += (torch.max(answer,\n",
    "                                            1)[1].view(label_batch.size()) == label_batch).sum()\n",
    "                dev_loss = criterion(answer, label_batch)\n",
    "            dev_acc = 100. * n_dev_correct / len(dev)\n",
    "\n",
    "            print(\n",
    "                dev_log_template.format(time.time() - start, epoch, iterations, 1 + batch_idx,\n",
    "                                        len(train_sampler),\n",
    "                                        100. * (1 + batch_idx) / len(train_sampler), loss.item(),\n",
    "                                        dev_loss.item(), train_acc, dev_acc))\n",
    "\n",
    "            # update best validation set accuracy\n",
    "            if dev_acc > best_dev_acc:\n",
    "\n",
    "                # found a model with better validation set accuracy\n",
    "\n",
    "                best_dev_acc = dev_acc\n",
    "                snapshot_prefix = os.path.join('results', 'best_snapshot')\n",
    "                snapshot_path = snapshot_prefix + '_devacc_{}_devloss_{}__iter_{}_model.pt'.format(\n",
    "                    dev_acc, dev_loss.item(), iterations)\n",
    "\n",
    "                # save model, delete previous 'best_snapshot' files\n",
    "                torch.save(model, snapshot_path)\n",
    "                for f in glob.glob(snapshot_prefix + '*'):\n",
    "                    if f != snapshot_path:\n",
    "                        os.remove(f)\n",
    "\n",
    "        elif iterations % 1000 == 0:\n",
    "\n",
    "            # print progress message\n",
    "            print(\n",
    "                log_template.format(time.time() - start, epoch, iterations, 1 + batch_idx,\n",
    "                                    len(train_sampler), 100. * (1 + batch_idx) / len(train_sampler),\n",
    "                                    loss.item(), ' ' * 8, n_correct / n_total * 100, ' ' * 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02566d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:55:16.266539Z",
     "iopub.status.busy": "2024-06-23T03:55:16.265537Z",
     "iopub.status.idle": "2024-06-23T03:55:28.528862Z",
     "shell.execute_reply": "2024-06-23T03:55:28.527703Z"
    },
    "papermill": {
     "duration": 12.415068,
     "end_time": "2024-06-23T03:55:28.531112",
     "exception": false,
     "start_time": "2024-06-23T03:55:16.116044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f7ffc",
   "metadata": {
    "papermill": {
     "duration": 0.1507,
     "end_time": "2024-06-23T03:55:28.835647",
     "exception": false,
     "start_time": "2024-06-23T03:55:28.684947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5940c0",
   "metadata": {
    "papermill": {
     "duration": 0.151008,
     "end_time": "2024-06-23T03:55:29.136077",
     "exception": false,
     "start_time": "2024-06-23T03:55:28.985069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39860.621581,
   "end_time": "2024-06-23T03:55:32.187857",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-22T16:51:11.566276",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
